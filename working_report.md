# Working Document: Adding Energy Metrics to LMStudio/Ollama

---

## **Problem Statement**

Currently, tools like LMStudio and Ollama provide robust environments for running and experimenting with LLMs but lack built-in energy metrics. This omission makes it difficult for developers and researchers to:

1. **Measure Energy Consumption**: Understand the energy footprint of their models during training, fine-tuning, or inference.
2. **Optimize for Efficiency**: Identify energy-intensive processes and optimize them for sustainability.

3. **Report Environmental Impact**: Provide transparency about the environmental impact of their AI workflows.


---

## **Solution Proposal**

To address this gap, we propose integrating energy metrics into LMStudio and Ollama. This integration will enable users to monitor and analyze the energy consumption of their LLM workflows. The solution will include:

1. **Energy Monitoring Module**:
   - A lightweight module that tracks energy usage during model training, fine-tuning, and inference.
   


